import os
import sys
import time
import random
import networkx as nx
from utils.utils import *
from ext.gensim_wrapper.models.word2vec import Word2VecWrapper, CombineSentences

sys.path.append("../ext/deepwalk/deepwalk")
sys.path.append("../ext/node2vec/src")
lda_exe_path = "../ext/gibbslda/lda"

try:
    import graph as deepwalk
    import node2vec
    if not os.path.exists(lda_exe_path):
        raise ImportError
except ImportError:
    raise ImportError("An error occurred during loading the external libraries!")


class TNE:
    def __init__(self, graph):
        self.graph = graph
        self.corpus = []
        self.params = {}

    def perform_random_walks(self, method):

        initial_time = time.time()
        # Generate a corpus

        if method == "deepwalk":
            number_of_walks = self.params['number_of_walks']
            walk_length = self.params['walk_length']
            alpha = self.params['alpha']

            # Temporarily generate the edge list
            with open("../temp/graph_deepwalk.edgelist", 'w') as f:
                for line in nx.generate_edgelist(self.graph, data=False):
                    f.write("{}\n".format(line))

            dwg = deepwalk.load_edgelist("../temp/graph.edgelist", undirected=True)
            self.corpus = deepwalk.build_deepwalk_corpus(G=dwg, num_paths=number_of_walks,
                                                         path_length=walk_length,
                                                         alpha=alpha,
                                                         rand=random.Random(0))

        elif method == "node2vec":

            number_of_walks = self.params['number_of_walks']
            walk_length = self.params['walk_length']
            p = self.params['p']
            q = self.params['q']

            for edge in self.graph.edges():
                self.graph[edge[0]][edge[1]]['weight'] = 1
            G = node2vec.Graph(nx_G=self.graph, p=p, q=q, is_directed=False)
            G.preprocess_transition_probs()
            self.corpus = G.simulate_walks(num_walks=number_of_walks, walk_length=walk_length)

        else:
            raise ValueError("Invalid method name!")

        print("The corpus was generated in {:.2f} secs | {}".format(time.time() - initial_time))

    def save_corpus(self, corpus_file, with_title=False):

        # Save the corpus
        with open(corpus_file, "r") as f:

            if with_title is True:
                f.write(u"{}\n".format(self.params['number_of_nodes'] * self.params['number_of_walks']))

            for walk in self.corpus:
                f.write(u"{}\n".format(u" ".join(v for v in walk)))

    def extract_node_embedding(self, node_embedding_file, workers=3):

        # Extract the node embeddings
        model = Word2VecWrapper(sentences=self.corpus,
                                size=self.params["d"],
                                window=self.params["window_size"],
                                sg=1, hs=1,
                                workers=workers,
                                min_count=0)

        # Save the node embeddings
        model.wv.save_word2vec_format(fname=node_embedding_file)

    def run_lda(self, alpha, beta, number_of_iters, number_of_topics, lda_corpus_path):

        initial_time = time.time()
        # Run GibbsLDA++
        cmd = "{} -est "
        cmd += "-dfile {} ".format(lda_corpus_path)
        cmd += "-alpha {} ".format(alpha)
        cmd += "-beta {} ".format(beta)
        cmd += "-ntopics {} ".format(number_of_topics)
        cmd += "-niters {} ".format(number_of_iters)
        cmd += "-savestep {} ".format(number_of_iters+1)
        os.system(cmd)
        print("-> The LDA algorithm run in {:.2f} secs".format(time.time() - initial_time))

    def extract_topic_embedding(self):
        # Define the paths for the files generated by GibbsLDA++
        wordmapfile = "./temp/wordmap.txt"
        tassignfile = "./temp/model-final.tassign"
        lda_node_corpus = "./temp/lda_node.file"
        lda_topic_corpus = "./temp/lda_topic.file"
        phi_file = "./temp/model-final.phi"

        initial_time = time.time()
        # Convert node corpus to the corresponding topic corpus
        topic_corpus = convert_node2topic(tassignfile)
        # Generate sentences in the following form: (node, topic)
        #corpus.save(filename=lda_node_corpus, with_title=False, save_one_line=False)
        # Construct the tuples (word, topic) with each word in the corpus and its corresponding topic assignment
        combined_sentences = CombineSentences(self.corpus, topic_corpus)
        # Extract the topic embeddings
        model.train_topic(number_of_topics, combined_sentences)

        # Save the topic embeddings
        model.wv.save_word2vec_topic_format(fname=topic_embedding_file)
        print(
        "-> The topic embeddings were generated and saved in {:.2f} secs | {}".format((time.time() - initial_time),
                                                                                      node_embedding_file))
